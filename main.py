from contextlib import asynccontextmanager

import cv2 as cv
import keras
from fastapi import FastAPI, Response, UploadFile
from fastapi.middleware.cors import CORSMiddleware

from functions import classify_boxes, get_bounding_boxes, read_image
from models import AnnotatedBoxes, Boxes, Confidence, Labels

ml_models = {}


@asynccontextmanager
async def lifespan(app: FastAPI):
    # Load the ML model
    ml_models["box_classifier"] = keras.saving.load_model("model.keras")
    yield
    # Clean up the ML models and release the resources
    ml_models.clear()


app = FastAPI(lifespan=lifespan)
origins = [
    "http://localhost",
    "http://localhost:3000",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# TODO: Como posso colocar n templates?
# TODO: Aplicar a previsÃ£o em cima do array de imagens ao inves de prever uma a uma.
# TODO: Retornar a probabilidade de cada classe ao inves de so a classe prevista.


@app.post("/find_boxes/")
async def find_boxes(test_image: UploadFile, box_images: list[UploadFile], threshold: float = 0.5) -> Boxes:
    img_rgb = await read_image(test_image, flags=cv.IMREAD_COLOR)
    template = [await read_image(box_image, flags=cv.IMREAD_GRAYSCALE) for box_image in box_images]

    boxes = get_bounding_boxes(img_rgb, template, threshold)

    return Boxes(root=boxes)


@app.post("/find_answers/")
async def find_answers(
    test_image: UploadFile, box_images: list[UploadFile], threshold: float = 0.5, prediction_threshold: float = 0.9
) -> AnnotatedBoxes:
    img_rgb = await read_image(test_image, flags=cv.IMREAD_COLOR)
    template = [await read_image(box_image, flags=cv.IMREAD_GRAYSCALE) for box_image in box_images]

    boxes = get_bounding_boxes(img_rgb, template, threshold)

    responses, confidence = classify_boxes(img_rgb, boxes, ml_models["box_classifier"], prediction_threshold)

    return AnnotatedBoxes(
        boxes=Boxes(root=boxes), labels=Labels(root=responses), confidence=Confidence(root=confidence)
    )


@app.post(
    "/mark_boxes/",  # Set what the media type will be in the autogenerated OpenAPI specification.
    # fastapi.tiangolo.com/advanced/additional-responses/#additional-media-types-for-the-main-response
    responses={200: {"content": {"image/png": {}}}},
    # Prevent FastAPI from adding "application/json" as an additional
    # response media type in the autogenerated OpenAPI specification.
    # https://github.com/tiangolo/fastapi/issues/3258
    response_class=Response,
)
async def mark_boxes(test_image: UploadFile, box_images: list[UploadFile], threshold: float = 0.5):
    img_rgb = await read_image(test_image, flags=cv.IMREAD_COLOR)
    template = [await read_image(box_image, flags=cv.IMREAD_GRAYSCALE) for box_image in box_images]

    boxes = get_bounding_boxes(img_rgb, template, threshold)

    for box in boxes:
        cv.rectangle(img_rgb, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), 2)

    _, encoded_img = cv.imencode(".PNG", img_rgb)

    return Response(content=encoded_img.tostring(), media_type="image/png")


@app.post(
    "/mark_answers/",  # Set what the media type will be in the autogenerated OpenAPI specification.
    # fastapi.tiangolo.com/advanced/additional-responses/#additional-media-types-for-the-main-response
    responses={200: {"content": {"image/png": {}}}},
    # Prevent FastAPI from adding "application/json" as an additional
    # response media type in the autogenerated OpenAPI specification.
    # https://github.com/tiangolo/fastapi/issues/3258
    response_class=Response,
)
async def mark_answers(
    test_image: UploadFile, box_images: list[UploadFile], threshold: float = 0.5, prediction_threshold: float = 0.9
):
    img_rgb = await read_image(test_image, flags=cv.IMREAD_COLOR)
    template = [await read_image(box_image, flags=cv.IMREAD_GRAYSCALE) for box_image in box_images]

    boxes = get_bounding_boxes(img_rgb, template, threshold)

    responses, _ = classify_boxes(img_rgb, boxes, ml_models["box_classifier"], prediction_threshold)

    mapping = {"empty": (0, 0, 255), "confirmed": (255, 0, 255)}

    for box, response in zip(boxes, responses):
        color = mapping[response]
        cv.rectangle(img_rgb, (box[0], box[1]), (box[2], box[3]), color, 2)

    _, encoded_img = cv.imencode(".PNG", img_rgb)

    return Response(content=encoded_img.tostring(), media_type="image/png")
